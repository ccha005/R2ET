# [NeurIPS 2024] Training for Stable Explanation for Free

Official implementation of **R2ET**, introduced in the NeurIPS 2024 paper _â€œTraining for Stable Explanation for Freeâ€_ by Chen _et al._  [Link](https://proceedings.neurips.cc/paper_files/paper/2024/hash/0626822954674a06ccd9c234e3f0d572-Abstract-Conference.html).

## ğŸ“˜ Overview

R2ET empowers machine learning models with **stable and faithful explanations**, mitigating malicious manipulation of feature saliency without incurring heavy adversarial training costs. Key innovations include:

- A novel **ranking-based stability metric** ("explanation thickness") measuring topâ€‘k salient feature consistency. 
- A **regularization-driven training algorithm** with theoretical guarantees that explanations remain stable across perturbations. 
- Strong **provable links** to multiâ€‘objective optimization and certified robustnessâ€”all while avoiding expensive adversarial loops. 

Extensive experiments across diverse modalities and architectures highlight R2ETâ€™s effectiveness against stealthy attacks and its generalization across explanation methods. 



## â³ What is included

- ğŸ§ª Preprocessed datasets and notebooks showcasing usage
  
  pretrain.py (optional)
  
- ğŸ“Š Benchmarking against baseline robustness methods
  
  batch_retrain.py
  
- ğŸ“‚ Codes for training and evaluation
  
  eval_retrain.py



## ğŸ¯ Why R2ET Matters

1. **Trustworthy AI deployments** â€“ ensures model explanations cannot be trivially disrupted.  
2. **Efficient training** â€“ no need for adversarial sample generation loops.  
3. **Theoretically grounded** â€“ certified stability with mathematical guarantees.



## ğŸ§© Get Involved

- â­ Star the repo to show support!
- ğŸ Submit issues if you spot bugs or need help.
- ğŸ¤ Contributions welcomeâ€”especially with code, docs, or CI pipelines.



## ğŸ“„ Citation

If you find R2ET useful, please cite:

```bibtex
@inproceedings{chen2024training,
  author    = {Chen, Chao and Guo, Chenghua and Chen, Rufeng and Ma, Guixiang and Zeng, Ming and Liao, Xiangwen and Zhang, Xi and Xie, Sihong},
  title     = {Training for Stable Explanation for Free},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {37},
  year      = {2024},
  pages     = {3421--3457},
}
